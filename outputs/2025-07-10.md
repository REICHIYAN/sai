最新のマルチモーダル大規模言語モデルは画像ベースのQ&Aを可能にしましたが、CLIPの視覚エンコーダーは細部を見逃しがちです。そこで、事前学習済みのテキストから画像への拡散モデルを視覚エンコーダーとして利用し、
[Link](http://arxiv.org/abs/2507.07106v1)

