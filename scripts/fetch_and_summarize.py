import os
import openai
import arxiv
import argparse
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

# ==== åˆæœŸåŒ– ====
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# ==== è¨­å®š ====
CATEGORY = "cs.*"
MAX_RESULTS = 1
OUTPUT_DIR = Path("outputs")
SEEN_IDS_FILE = Path("seen/seen_ids.txt")

OUTPUT_DIR.mkdir(exist_ok=True)
SEEN_IDS_FILE.parent.mkdir(exist_ok=True)
if not SEEN_IDS_FILE.exists():
    SEEN_IDS_FILE.touch()

# ==== é‡è¤‡ãƒã‚§ãƒƒã‚¯ ====
def load_seen_ids() -> set:
    with open(SEEN_IDS_FILE, "r", encoding="utf-8") as f:
        return set(line.strip() for line in f.readlines())

def save_seen_id(arxiv_id: str) -> None:
    with open(SEEN_IDS_FILE, "a", encoding="utf-8") as f:
        f.write(f"{arxiv_id}\n")

# ==== è«–æ–‡å–å¾—ï¼ˆå¼·åˆ¶å–å¾—ï¼‰====
def get_first_unseen_paper():
    seen_ids = load_seen_ids()

    search = arxiv.Search(
        query=f"cat:{CATEGORY}",
        max_results=MAX_RESULTS * 10,
        sort_by=arxiv.SortCriterion.SubmittedDate,
    )

    for result in arxiv.Client().results(search):
        arxiv_id = result.get_short_id()
        if arxiv_id in seen_ids:
            continue

        save_seen_id(arxiv_id)
        return [result]

    return []

# ==== è¦ç´„å‡¦ç† ====
def summarize(text: str, lang: str) -> str:
    if lang == "en":
        prompt = f"Summarize the following abstract in English in 200 to 280 characters:\n{text}"
    else:
        prompt = f"æ¬¡ã®è‹±æ–‡è¦ç´„ã‚’ã€æ—¥æœ¬èªã§140ã€œ200æ–‡å­—ã«è¦ç´„ã—ã¦ãã ã•ã„ï¼š\n{text}"

    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "You are a concise academic assistant."},
            {"role": "user", "content": prompt},
        ],
        temperature=0.3,
    )
    return response.choices[0].message.content.strip()

# ==== ã‚¿ã‚°è£œå®Œ ====
def generate_tags(title: str, summary: str) -> list[str]:
    prompt = f"""ä»¥ä¸‹ã¯è«–æ–‡ã®ã‚¿ã‚¤ãƒˆãƒ«ã¨è¦ç´„ã§ã™ã€‚
ã“ã®è«–æ–‡ã®ä¸»ãªæŠ€è¡“ãƒ»ç ”ç©¶åˆ†é‡ã‚’ã€è‹±èªã®ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°å½¢å¼ã§æœ€å¤§3ã¤å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼š#LLM #ReinforcementLearningï¼‰ã€‚

ã‚¿ã‚¤ãƒˆãƒ«ï¼š
{title}

è¦ç´„ï¼š
{summary}
"""
    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "You are an expert in machine learning research topics."},
            {"role": "user", "content": prompt},
        ],
        temperature=0.3,
    )
    tags_text = response.choices[0].message.content.strip()
    tags = [tag.strip() for tag in tags_text.split() if tag.startswith("#")]
    return tags[:3]

# ==== Markdownå‡ºåŠ› ====
def format_entry(paper, summary_en, summary_ja, tags: list[str]) -> str:
    return f"""## ğŸ“ {paper.title} ({paper.published.date()})

- ğŸ‡¬ğŸ‡§ {summary_en}
- ğŸ‡¯ğŸ‡µ {summary_ja}
- ã‚¿ã‚°ï¼š{' '.join(tags)}
- ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ï¼š#{' '.join(paper.categories)}
- ğŸ”— [{paper.entry_id}]({paper.entry_id})
---
"""

# ==== å®Ÿè¡Œ ====
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--date", help="(ç„¡è¦–ã•ã‚Œã¾ã™) äº’æ›æ€§ã®ãŸã‚ã®å¼•æ•°", type=str)
    args = parser.parse_args()

    papers = get_first_unseen_paper()
    if not papers:
        print("ğŸ“¬ No new papers found.")
        return

    today_str = datetime.now().strftime("%Y-%m-%d")
    output_path = OUTPUT_DIR / f"{today_str}.md"

    with open(output_path, "w", encoding="utf-8") as f:
        for paper in papers:
            summary_en = summarize(paper.summary, lang="en")
            summary_ja = summarize(paper.summary, lang="ja")
            tags = generate_tags(paper.title, paper.summary)
            entry = format_entry(paper, summary_en, summary_ja, tags)
            f.write(entry + "\n")

    print(f"âœ… Summary written to {output_path}")

if __name__ == "__main__":
    main()
